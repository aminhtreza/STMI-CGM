{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import json\n",
    "import math\n",
    "from datetime import datetime,timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import pearsonr, mode\n",
    "from scipy.signal import savgol_filter\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "import firebase_admin\n",
    "import pyrebase\n",
    "\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from PIL import Image\n",
    "from datetime import timedelta\n",
    "from csv import reader\n",
    "import pandas as pd \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.style.use({'figure.facecolor':'white'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# configure firebase account settings and API output into a bucket\n",
    "def fireBaseConfigurator():\n",
    "    firebaseConfig = {\n",
    "        'apiKey': \"AIzaSyAM6q3xQ2MAAMAs_UxQsxM6XvKkFVJBiSo\",\n",
    "        'authDomain': \"stmicgm-1e16e.firebaseapp.com\",\n",
    "        'projectId': \"stmicgm-1e16e\",\n",
    "        'storageBucket': \"stmicgm-1e16e.appspot.com\",\n",
    "        'serviceAccount':\"stmicgm-1e16e-firebase-adminsdk-9vmvd-cf9c6a9e3e.json\",\n",
    "        'messagingSenderId': \"585212152936\",\n",
    "        'appId': \"1:585212152936:web:18b5cd88c69804cc24bfdd\",\n",
    "        'databaseURL': \"xxx\",\n",
    "        'measurementId': \"G-ZSXWR8JB6M\"\n",
    "    }\n",
    "    firebase=pyrebase.initialize_app(firebaseConfig)\n",
    "    myBucket=firebase.storage()\n",
    "    return myBucket\n",
    "\n",
    "# create folders for each participant\n",
    "def createParticipantDirectory(myBucket):\n",
    "    bucketFiles=myBucket.list_files()\n",
    "    participantNums=[]\n",
    "    for bucketFile in bucketFiles:\n",
    "        dirName=bucketFile.name\n",
    "        dirName=dirName[:dirName.rfind('/')]\n",
    "        participantNums.append(dirName)\n",
    "    participantNums=list(set(participantNums))\n",
    "\n",
    "    for participantNum in participantNums:\n",
    "        # make sure to change this directory to your own\n",
    "        dirName=os.path.join('/Users/aminreza/Desktop/data/AppleWatchFiles/',participantNum,'')\n",
    "        if not os.path.exists(dirName):\n",
    "            os.mkdir(dirName)\n",
    "\n",
    "# below function prints the last uploaded file by each participant. Uncomment the day section to choose specific days\n",
    "def lastUploaded(myBucket):\n",
    "    bucketFiles=myBucket.list_files()\n",
    "    for bucketFile in tqdm(bucketFiles):\n",
    "        fileName=bucketFile.name\n",
    "        try:\n",
    "            participantId=fileName[:fileName.rfind('/')]\n",
    "            if participantId == \"0\":\n",
    "                day=fileName[:fileName.rfind('-')]\n",
    "                #if day == \"0/10-23\":\n",
    "                #    print(\"participant\", participantId, \"timestamp\", fileName)\n",
    "                if fileName != \"0/errorLog\":\n",
    "                    lastFile = fileName\n",
    "                #print(\"day\", day)\n",
    "\n",
    "            if participantId == \"1\":\n",
    "                day=fileName[:fileName.rfind('-')]\n",
    "                # if day == \"1/10-25\":\n",
    "                #    print(\"participant\", participantId, \"timestamp\", fileName)\n",
    "                if fileName != \"1/errorLog\":\n",
    "                    lastFile1 = fileName\n",
    "                #print(\"day\", day)\n",
    "\n",
    "            if participantId == \"2\":\n",
    "                day=fileName[:fileName.rfind('-')]\n",
    "                # if day == \"1/10-25\":\n",
    "                #    print(\"participant\", participantId, \"timestamp\", fileName)\n",
    "                if fileName != \"2/errorLog\":\n",
    "                    lastFile2 = fileName\n",
    "                #print(\"day\", day)\n",
    "\n",
    "            if participantId == \"3\":\n",
    "                day=fileName[:fileName.rfind('-')]\n",
    "                # if day == \"1/10-25\":\n",
    "                #    print(\"participant\", participantId, \"timestamp\", fileName)\n",
    "                if fileName != \"3/errorLog\":\n",
    "                    lastFile3 = fileName\n",
    "                #print(\"day\", day)\n",
    "\n",
    "            if participantId == \"4\":\n",
    "                day=fileName[:fileName.rfind('-')]\n",
    "                # if day == \"1/10-25\":\n",
    "                #    print(\"participant\", participantId, \"timestamp\", fileName)\n",
    "                if fileName != \"4/errorLog\":\n",
    "                    lastFile4 = fileName\n",
    "                #print(\"day\", day)   \n",
    "        except:\n",
    "            print(\"error in file:\",fileName)\n",
    "\n",
    "    print(\"P0 Last uploaded file:\", lastFile)\n",
    "    print(\"P1 Last uploaded file:\", lastFile1)\n",
    "    print(\"P2 Last uploaded file:\", lastFile2)\n",
    "    print(\"P3 Last uploaded file:\", lastFile3)\n",
    "    print(\"P4 Last uploaded file:\", lastFile4)\n",
    "\n",
    "myBucket=fireBaseConfigurator()\n",
    "createParticipantDirectory(myBucket)\n",
    "# lastUploaded(myBucket)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# download the files for respective participant\n",
    "def fireBaseDownloader(myBucket, participant):\n",
    "    bucketFiles=myBucket.list_files()\n",
    "    for bucketFile in tqdm(bucketFiles):\n",
    "        fileName=bucketFile.name\n",
    "        try:\n",
    "            dirName=fileName[:fileName.rfind('/')]\n",
    "            fileName=os.path.basename(fileName)\n",
    "            if dirName == str(participant): \n",
    "                fileName=fileName.replace(\":\",\"-\")\n",
    "                # make sure to change this directory to your own\n",
    "                fileName=os.path.join('/Users/aminreza/Desktop/data/AppleWatchFiles/',dirName,fileName+'.txt')\n",
    "                if os.path.exists(fileName):\n",
    "                    continue\n",
    "                bucketFile.download_to_filename(fileName)  \n",
    "                # print(dirName, fileName)  \n",
    "        except:\n",
    "            print(\"error in file:\",fileName)\n",
    "\n",
    "# change participant number below and run code\n",
    "participant = 4\n",
    "fireBaseDownloader(myBucket, participant)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# utility function that returns a list of files\n",
    "def fileFinder(participant):\n",
    "    dataPath=os.path.join('/Users/aminreza/Desktop/data/AppleWatchFiles/')\n",
    "    fileList=[]\n",
    "    for root, dirs, files in os.walk(dataPath, topdown=False):\n",
    "        if root == \"/Users/aminreza/Desktop/data/\" + str(participant):\n",
    "            for name in files:\n",
    "                if 'error' in name:\n",
    "                    continue\n",
    "                fileList.append([os.path.join(root, name),os.path.basename(root)])\n",
    "    return fileList\n",
    "\n",
    "# process the core motion data frame. Function called in cmProcess \n",
    "def dfProcessorCm(fieldNumber,currentFile,deviceUID): \n",
    "    rawData=[]\n",
    "    fileHandle = open(currentFile, 'r')\n",
    "    fileContex=fileHandle.read()\n",
    "    fileHandle.close()\n",
    "    for line in fileContex.splitlines():\n",
    "        rawData.append(float(line))\n",
    "    if len(rawData) % fieldNumber!=0:\n",
    "        print(\"Houston we have a problem. The data length does not look right\")\n",
    "        return\n",
    "    sensorData=np.asarray(rawData).reshape(int(len(rawData)/fieldNumber),fieldNumber)\n",
    "    dfSensor=pd.DataFrame(sensorData,columns=['UnixTime','Ax','Ay','Az','Rx','Ry','Rz','Yaw','Roll','Pitch'])\n",
    "    dfSensor['UnixTime']+=1609459200 #Fixing the time offset enforced on the application side (also fixed the UTC difference)\n",
    "    dfSensor.insert(1,'Date',dfSensor['UnixTime'])\n",
    "    dfSensor['Date']=pd.to_datetime(dfSensor['Date'], unit='s')\n",
    "    dfSensor['Date']=dfSensor['Date'].dt.tz_localize('UTC').dt.tz_convert('US/Central')\n",
    "    dfSensor.insert(0,'UID',deviceUID)\n",
    "    return dfSensor\n",
    "\n",
    "# process the health kit data frame. Function called in hkProcess\n",
    "def dfProcessorHk(fieldNumber,currentFile,deviceUID): \n",
    "    rawData=[]\n",
    "    fileHandle = open(currentFile, 'r')\n",
    "    fileContex=fileHandle.read()\n",
    "    fileHandle.close()\n",
    "    for line in fileContex.splitlines():\n",
    "        rawData.append(float(line))\n",
    "    if len(rawData) % fieldNumber!=0:\n",
    "        print(\"Houston we have a problem. The data length does not look right\")\n",
    "        return\n",
    "    sensorData=np.asarray(rawData).reshape(int(len(rawData)/fieldNumber),fieldNumber)\n",
    "    dfSensor=pd.DataFrame(sensorData,columns=['UnixTime','heartRate','energyBurned','stepCount'])\n",
    "    # dfSensor['UnixTime']+=1609459200 #Fixing the time offset enforced on the application side (also fixed the UTC difference)\n",
    "    dfSensor.insert(1,'Date',dfSensor['UnixTime'])\n",
    "    dfSensor['Date']=pd.to_datetime(dfSensor['Date'], unit='s')\n",
    "    dfSensor['Date']=dfSensor['Date'].dt.tz_localize('UTC').dt.tz_convert('US/Central')\n",
    "    dfSensor.insert(0,'UID',deviceUID)\n",
    "    return dfSensor\n",
    "\n",
    "# process cm files into a data frame\n",
    "def cmProcess(fieldNumber, participant):\n",
    "    fileList=fileFinder(participant=participant)\n",
    "    fileList.sort()\n",
    "    counter=0\n",
    "    dfTotal = pd.DataFrame()\n",
    "    for element in tqdm(fileList):\n",
    "        currentFile=element[0]\n",
    "        deviceUID=element[1]\n",
    "        type=currentFile.split(\".\",1) # whether it's hk or cm\n",
    "        if type[1] == \"cm.txt\":\n",
    "            if counter==0:\n",
    "                dfTotal=dfProcessorCm(fieldNumber,currentFile,deviceUID)\n",
    "            else:\n",
    "                df=dfProcessorCm(fieldNumber,currentFile,deviceUID)\n",
    "                frames=[dfTotal,df]\n",
    "                dfTotal=pd.concat(frames)\n",
    "            counter+=1\n",
    "    \n",
    "    return dfTotal\n",
    "        \n",
    "# process cm files into a data frame\n",
    "def hkProcess(fieldNumber, participant):\n",
    "    fileList=fileFinder(participant=participant)\n",
    "    fileList.sort()\n",
    "    counter=0\n",
    "    # currentDay = \"05\" # used to pick days by days\n",
    "    dfTotal = pd.DataFrame()\n",
    "    for element in tqdm(fileList):\n",
    "        currentFile=element[0]\n",
    "        deviceUID=element[1]\n",
    "        type=currentFile.split(\".\",1) # whether it's hk or cm\n",
    "        if type[1] == \"hk.txt\":\n",
    "            # day = type[0]\n",
    "            # day = day.split(\"-\",4) # day[1] is the day from string\n",
    "            # if currentDay == day[1]:\n",
    "            if counter==0:\n",
    "                dfTotal=dfProcessorHk(fieldNumber,currentFile,deviceUID)\n",
    "            else:\n",
    "                df=dfProcessorHk(fieldNumber,currentFile,deviceUID)\n",
    "                frames=[dfTotal,df]\n",
    "                dfTotal=pd.concat(frames)\n",
    "            counter+=1\n",
    "        \n",
    "    return dfTotal\n",
    "        \n",
    "# change participant number and run code        \n",
    "participant = 4\n",
    "\n",
    "# dfAll=hkProcess(fieldNumber=4, participant=participant)\n",
    "# resultPath=os.path.join('/Users/aminreza/Desktop/data/', 'p' + str(participant) + '_hk_all.csv')\n",
    "# dfAll.to_csv(resultPath,index=False)\n",
    "\n",
    "dfAll=cmProcess(fieldNumber=10, participant=participant)\n",
    "resultPath=os.path.join('/Users/aminreza/Desktop/data/','p' + str(participant) + '_cm_all.csv')\n",
    "dfAll.to_csv(resultPath,index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def processSqlite(directory, participant):\n",
    "    # Create a SQL connection to our SQLite database\n",
    "    con = sqlite3.connect(directory)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    header = ['startTime', 'finishTime', 'activityType', 'activityDetail', 'travelFrom', 'travelTo']\n",
    "\n",
    "    with open('/Users/aminreza/Desktop/data/UserInputted/p' + str(participant) + 'Activities.csv', 'w', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        # write the header\n",
    "        writer.writerow(header)\n",
    "        # The result of a \"cursor.execute\" can be iterated over by row\n",
    "        for row in cur.execute('SELECT * FROM ZACTIVITIES;'):\n",
    "            travelFrom = \"\"\n",
    "            travelTo = \"\"\n",
    "            startTime = row[4] + 978307200\n",
    "            startTime = datetime.utcfromtimestamp(startTime).strftime('%m/%d/%y %H:%M')\n",
    "            finishTime = row[3] + 978307200\n",
    "            finishTime = datetime.utcfromtimestamp(finishTime).strftime('%m/%d/%y %H:%M')\n",
    "            activityType = row[6]\n",
    "            activityDetail = row[5]\n",
    "            if row[6] == \"Travel\":\n",
    "                travelFrom = row[7]\n",
    "                travelTo = row[8]\n",
    "\n",
    "            data = [startTime, finishTime, activityType, activityDetail, travelFrom, travelTo]\n",
    "            writer.writerow(data)\n",
    "        # write the data\n",
    "\n",
    "    header = ['MealName', 'startTime', 'FinishTime', 'Calories', 'Carbs', 'Fat', 'Protein', 'Ingredients', 'Portions']\n",
    "    with open('/Users/aminreza/Desktop/data/UserInputted/p' + str(participant) +'Meals.csv', 'w', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        for row in cur.execute('SELECT * FROM ZMEAL ORDER by z_pk;'):\n",
    "            mealName = row[10]\n",
    "            startDate = row[8] + 978307200\n",
    "            # print(\"Start time:\", datetime.utcfromtimestamp(startDate).strftime('%m/%d/%y %H:%M'))\n",
    "            startTime = datetime.utcfromtimestamp(startDate).strftime('%m/%d/%y %H:%M')\n",
    "            finishDate = row[6] + 978307200\n",
    "            # print(\"Finish time:\", datetime.utcfromtimestamp(finishDate).strftime('%%m/%d/%y %H:%M'))\n",
    "            finishTime = datetime.utcfromtimestamp(finishDate).strftime('%m/%d/%y %H:%M')\n",
    "            \n",
    "            calories = row[3]\n",
    "            carbs = row[4]\n",
    "            fat = row[5]\n",
    "            protein = row[7]\n",
    "            ingredients = row[9]\n",
    "            portions = row[11]\n",
    "\n",
    "            data = [mealName, startTime, finishTime, calories, carbs, fat, protein, ingredients, portions]\n",
    "            writer.writerow(data)\n",
    "\n",
    "participant = 1\n",
    "directory = \"/Users/aminreza/Desktop/data/UserInputted/p\" + str(participant) +\"/AppData/Library/ApplicationSupport/STMI-CGMcoreData.sqlite\"\n",
    "processSqlite(directory, participant)            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def evaluateCVS():\n",
    "    with open('/Users/aminreza/Desktop/data/CGM/p1Combined.csv', 'r') as read_obj:\n",
    "        # pass the file object to reader() to get the reader object\n",
    "        csv_reader = reader(read_obj)\n",
    "        # Iterate over each row in the csv using reader object\n",
    "        for row in csv_reader:\n",
    "            # row variable is a list that represents a row in csv\n",
    "            # print(\"less\",row[2])\n",
    "            # print(\"less CGM\",row[3])\n",
    "            # print(\"more\",row[5])\n",
    "            # print(\"more CGM\",row[1])\n",
    "            # datetime_object = datetime.strptime(row[2], '%m/%d/%y %H:%M %p')\n",
    "            if (row[4] != \"dexcomTime\" and row[4] != \"\") :\n",
    "                d = datetime.strptime(row[4], '%m/%d/%y %H:%M')\n",
    "                finaltime = d + timedelta(minutes=3)\n",
    "                print(\"time + 500\", datetime.strftime(finaltime, '%m/%d/%y %H:%M %p'))\n",
    "            # if row[3]\n",
    "\n",
    "# this function was created to assist with processing variables. It's only a developer tool and doesn't do anything\n",
    "evaluateCVS()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "def matchCGMtimes(directory, participant):\n",
    "    file = pd.read_csv(directory + 'Combined.csv')\n",
    "    dexcomTime = file.dexcomTime # longer\n",
    "    dexcomRead = file.dexcomRead\n",
    "    flTime = file.flTime # shorter\n",
    "    flRead = file.flRead\n",
    "\n",
    "    # remove null entries from list\n",
    "    flTime = flTime.dropna()\n",
    "    flRead = flRead.dropna()\n",
    "    dexcomTime = dexcomTime.dropna()\n",
    "    dexcomRead = dexcomRead.dropna()\n",
    "\n",
    "    matching=[]\n",
    "    header = ['Time', 'Dexcom', 'Abbot']\n",
    "\n",
    "    # second change the name of csv file according to p<id>\n",
    "    with open(directory + 'p4Processed.csv', 'w', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header) # write the header\n",
    "        for i in range(0,len(dexcomTime)): \n",
    "            dt = datetime.strptime(dexcomTime[i], '%m/%d/%y %H:%M')\n",
    "            for j in range(0,len(flTime)):\n",
    "                ft = datetime.strptime(flTime[j], '%m/%d/%y %H:%M')\n",
    "                if dt < ft + timedelta(minutes=3) and dt > ft - timedelta(minutes=3):\n",
    "                    print(\"dt: \", dt, \"ft: \", ft)\n",
    "                    row = [dexcomTime[i],dexcomRead[i],flRead[j]]\n",
    "                    break\n",
    "                else: \n",
    "                    row = [dexcomTime[i],dexcomRead[i],\"\"]\n",
    "            writer.writerow(row)\n",
    "\n",
    "    participant = 1\n",
    "    directory = '/Users/aminreza/Desktop/data/CGM/p' + str(participant)\n",
    "    matchCGMtimes()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('amin': conda)"
  },
  "interpreter": {
   "hash": "2219408e8cdbd99423de145d7a2d231234bac134d9415d1e15bc2aea1989fbaf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}